{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RadNLP\n",
    "## *Rad*iology NLP or\n",
    "## *Rad* (as in cool) NLP or\n",
    "## *[Fill in the Blank]* NLP\n",
    "\n",
    "RadNLP is a package that builds upon the [pyConTextNLP]() algorithm's sentence-level text processing to perform simple document-level classification. The package also contains a number of functions for identifying sections of reports, identifing and eliminating boiler-plate text, etc.\n",
    "\n",
    "In this notebook I will demonstrate radnlp's most basic functionality: given a text of interest create an overall document classification. The classifiction uses a simple maximum function: for each concept marked in a report the most \"positive\" occurance is selected to characterize the report for that concept.\n",
    "\n",
    "## Report Schema and *positivity*\n",
    "\n",
    "The document classification is based on schema that combines multiple concepts (e.g. existence, certitude, severity) into a single ordinal scale. The RadNLP GitHub repository includes a knowledge base directory (KBs) contains the schema we ahve previously developed for critical findings projects. It is included below:\n",
    "\n",
    "```Python\n",
    "# Lines that start with the # symbol are comments and are ignored\n",
    "# The schema consists of a numeric value, followed by a label (e.g. \"AMBIVALENT\"), \n",
    "# followed by a Python express that can evaluate to True or False\n",
    "# The Python expression uses LABELS from the rules. processReports.py will substitute \n",
    "# the LABEL with any matched values identified from \n",
    "# the corresponding rules\n",
    "1,AMBIVALENT,DISEASE_STATE == 2\n",
    "2,Negative/Certain/Acute,DISEASE_STATE == 0 and CERTAINTY_STATE == 1\n",
    "3,Negative/Uncertain/Chronic,DISEASE_STATE == 0 and CERTAINTY_STATE == 0 and ACUTE_STATE == 0\n",
    "4,Positive/Uncertain/Chronic,DISEASE_STATE == 1 and CERTAINTY_STATE == 0 and ACUTE_STATE == 0 \n",
    "5,Positive/Certain/Chronic,DISEASE_STATE == 1 and CERTAINTY_STATE == 1 and ACUTE_STATE == 0 \n",
    "6,Negative/Uncertain/Acute,DISEASE_STATE == 0 and CERTAINTY_STATE == 0 \n",
    "7,Positive/Uncertain/Acute,DISEASE_STATE == 1 and CERTAINTY_STATE == 0 and ACUTE_STATE == 1 \n",
    "8,Positive/Certain/Acute,DISEASE_STATE == 1 and CERTAINTY_STATE == 1 and ACUTE_STATE == 1 \n",
    "```\n",
    "\n",
    "A key idea is **\"a Python express that can evaluate to True or False\"**.\n",
    "\n",
    "The ``radnlp.schema`` subpackage contains functions for reading schema and applying the schema to the pyConTextNLP findings given ``rules`` specified by the user.\n",
    "\n",
    "There are two key functions in ``radnlp.schema``:\n",
    "\n",
    "```Python\n",
    "def instantiate_schema(values, rule):\n",
    "    \"\"\"\n",
    "    evaluates rule by substituting values into rule and evaluating the resulting literal.\n",
    "    This is currently insecure\n",
    "        * \"For security the ast.literal_eval() method should be used.\"\n",
    "    \"\"\"\n",
    "    r = rule\n",
    "    for k in values.keys():\n",
    "        r = r.replace(k, values[k].__str__())\n",
    "    #return ast.literal_eval(r)\n",
    "    return eval(r)\n",
    "\n",
    "def assign_schema(values, rules):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    for k in rules.keys():\n",
    "        if instantiate_schema(values, rules[k][1]):\n",
    "            return k\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``radnlp`` Rules\n",
    "\n",
    "``radnlp`` uses rule files to specify rules that define how particular pyConTextNLP findings relate to radnlp concepts. For example, in the ``classificationRules3.csv`` provided in KBs, we provide a rules that state:\n",
    "\n",
    "* The default disease state is 1. \n",
    "* ``PROBABLE_EXISTENCE`` AND  ``DEFINITE_EXISTENCE`` map to a disease state of 1\n",
    "\n",
    "Rules as currently indicated are not quite general and reflect paraticular use cases we were working on.\n",
    "\n",
    "### Types of Rules\n",
    "\n",
    "#### We currently support three rules:\n",
    "\n",
    "1. ``CLASSIFICAITON_RULE``: these are the rules that relate to disease, temporality, and certainty\n",
    "1. ``CATEGORY_RULE``: these are only partially developed concepts that attempt to address combinatorics problems in pyConTextNLP by making default findings more general (e.g. ``infaract``) and then tries to create more specific findings by attaching anatomic locations to the findings (e.g. an ``infarct`` becomes a critical finding when attached to an anatomic concept like ``brain_anatomy`` or ``heart_anatomy``.\n",
    "1. ``SEVERITY_RULE``: Again, not fully developed but relates to extracting severity concepts (e.g. ``large`` or 4.3 cm).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "# Lines that start with the # symbol are comments and are ignored,,,,,,,,,,,,,\n",
    "# processReport current has three types of rules: @CLASSIFICATION_RULE, @CATEGORY_RULE, and @SEVERITY_RULE,,,,,,,,,,,\n",
    "# classification rules would be for things like disease_state, certainty_state, temporality state,,,,,,,,,,,\n",
    "# For each classification_rule set,\" there is a rule label (e.g. \"\"DISEASE_STATE\"\". This must match\",,,,,,,,,,,,\n",
    "# the terms used in the schema file,,,,,,,,,,,,,\n",
    "# Each rule set requires a DEFAULT which is the schema value to be returned if no rule conditions are satisifed,,,,,,,,,,,,,\n",
    "# Each rule set has zero or more rules consisting of a schema value to be returned if the rule evaluates to true,,,,,,,,,,,,,\n",
    "# A rule evalutes to true if the target is modified by one or more of the ConText CATEGORIES listed following,,,,,,,,,,,,,\n",
    "@CLASSIFICATION_RULE,DISEASE_STATE,RULE,0,DEFINITE_NEGATED_EXISTENCE,PROBABLE_NEGATED_EXISTENCE,FUTURE,INDICATION,PSEUDONEG,,,,,\n",
    "@CLASSIFICATION_RULE,DISEASE_STATE,RULE,2,AMBIVALENT_EXISTENCE,,,,,,,,,\n",
    "@CLASSIFICATION_RULE,DISEASE_STATE,RULE,1,PROBABLE_EXISTENCE,DEFINITE_EXISTENCE,,,,,,,,\n",
    "@CLASSIFICATION_RULE,DISEASE_STATE,DEFAULT,1,,,,,,,,,,\n",
    "@CLASSIFICATION_RULE,CERTAINTY_STATE,RULE,0,PROBABLE_NEGATED_EXISTENCE,AMBIVALENT_EXISTENCE,PROBABLE_EXISTENCE,,,,,,,\n",
    "@CLASSIFICATION_RULE,CERTAINTY_STATE,DEFAULT,1,,,,,,,,,,\n",
    "@CLASSIFICATION_RULE,ACUTE_STATE,RULE,0,HISTORICAL,,,,,,,,,\n",
    "@CLASSIFICATION_RULE,ACUTE_STATE,DEFAULT,1,,,,,,,,,,\n",
    "#CATEGORY_RULE rules specify what Findings (e.g. DVT) can have the category modified by the following ANATOMIC modifies,,,,,,,,,,,,,\n",
    "@CATEGORY_RULE,DVT,LOWER_DEEP_VEIN,UPPER_DEEP_VEIN,HEPATIC_VEIN,PORTAL_SYSTEM_VEIN,PULMONARY_VEIN,RENAL_VEIN,SINUS_VEIN,LOWER_SUPERFICIAL_VEIN,UPPER_SUPERFICIAL_VEIN,VARICOCELE,ARTERIAL,NON_VASCULAR\n",
    "@CATEGORY_RULE,INFARCT,BRAIN_ANATOMY,HEART_ANATOMY,OTHER_CRITICAL_ANATOMY,,,,,,,,,\n",
    "@CATEGORY_RULE,ANEURYSM,AORTIC_ANATOMY,,,,,,,,,,,\n",
    "#SEVERITY_RUlE specifiy which targets to try to obtain severity measures for,,,,,,,,,,,,,\n",
    "@SEVERITY_RULE,AORTIC_ANATOMY_ANEURYSM,SEVERITY,,,,,,,,,,,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Licensing\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brian/anaconda/envs/uuds4health/lib/python3.5/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import radnlp.rules as rules\n",
    "import radnlp.schema as schema\n",
    "import radnlp.utils as utils\n",
    "import radnlp.classifier as classifier\n",
    "import radnlp.split as split\n",
    "\n",
    "from IPython.display import clear_output, display, HTML\n",
    "from IPython.html.widgets import interact, interactive, fixed\n",
    "import io\n",
    "from IPython.html import widgets # Widget definitions\n",
    "import pyConTextNLP.itemData as itemData\n",
    "\n",
    "from pyConTextNLP.display.html import mark_document_with_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Data\n",
    "\n",
    "Below are two example radiology reports pulled from the MIMIC2 demo data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reports = [\"\"\"1.  Pulmonary embolism with  filling defects noted within the upper and lower\n",
    "     lobar branches of the right main pulmonary artery.\n",
    "     2.  Bilateral pleural effusions, greater on the left.\n",
    "     3.  Ascites.\n",
    "     4.  There is edema of the gallbladder wall, without any evidence of\n",
    "     distention, intra- or extra-hepatic biliary dilatation.  This, along with\n",
    "     stranding within the mesentery, likely represents third spacing of fluid.\n",
    "     5.  There are several wedge shaped areas of decreased perfusion within the\n",
    "     spleen, which may represent splenic infarcts.\n",
    "     \n",
    "     Results were discussed with Dr. [**First Name8 (NamePattern2) 15561**] [**Last Name (NamePattern1) 13459**] \n",
    "     at 8 pm on [**3099-11-6**].\"\"\",\n",
    "           \n",
    "    \"\"\"1. Filling defects within the subsegmental arteries in the region\n",
    "     of the left lower lobe and lingula and within the right lower lobe consistent\n",
    "     with pulmonary emboli.\n",
    "     \n",
    "     2. Small bilateral pleural effusions with associated bibasilar atelectasis.\n",
    "     \n",
    "     3. Left anterior pneumothorax.\n",
    "     \n",
    "     4. No change in the size of the thoracoabdominal aortic aneurysm.\n",
    "     \n",
    "     5. Endotracheal tube 1.8 cm above the carina. NG tube within the stomach,\n",
    "     although the tip is pointed superiorly toward the fundus.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define lcoations of knowledge, schema, and rules files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getOptions():\n",
    "    \"\"\"Generates arguments for specifying database and other parameters\"\"\"\n",
    "    options = {}\n",
    "    options['lexical_kb'] = [\"https://raw.githubusercontent.com/chapmanbe/pyConTextNLP/master/KB/lexical_kb_04292013.tsv\", \n",
    "                             \"https://raw.githubusercontent.com/chapmanbe/pyConTextNLP/master/KB/criticalfinder_generalized_modifiers.tsv\"]\n",
    "    options['domain_kb'] = [\"https://raw.githubusercontent.com/chapmanbe/pyConTextNLP/master/KB/pe_kb.tsv\"]#[os.path.join(DATADIR2,\"pe_kb.tsv\")]\n",
    "    options[\"schema\"] = \"https://raw.githubusercontent.com/chapmanbe/RadNLP/master/KBs/schema2.csv\"#\"file specifying schema\"\n",
    "    options[\"rules\"] = \"https://raw.githubusercontent.com/chapmanbe/RadNLP/master/KBs/classificationRules3.csv\" # \"file specifying sentence level rules\")\n",
    "    return options\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define report analysis\n",
    "\n",
    "For every report we do two steps\n",
    "\n",
    "1. Markup all the sentences in the report based on the provided targets and modifiers\n",
    "1. Given this markup we apply our rules and schema to generate a document classification.\n",
    "\n",
    "``radnlp`` provides functions to do both of these steps:\n",
    "\n",
    "1. ``radnlp.utils.mark_report`` takes lists of modifiers and targets and generates a pyConTextNLP document graph\n",
    "1. ``radnlp.classify.classify_document_targets`` takes the document graph, rules, and schema and generates document classification for each identified concept.\n",
    "\n",
    "Because pyConTextNLP operates on sentences we split the report into sentences. In this function we use ``radnlp.split.get_sentences`` which is simply a wrapper around ``textblob`` for splitting the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyze_report(report, modifiers, targets, rules, schema):\n",
    "    \"\"\"\n",
    "    given an individual radiology report, creates a pyConTextGraph\n",
    "    object that contains the context markup\n",
    "    report: a text string containing the radiology reports\n",
    "    \"\"\"\n",
    "    \n",
    "    markup = utils.mark_report(split.get_sentences(report),\n",
    "                         modifiers,\n",
    "                         targets)\n",
    "    return  classify.classify_document_targets(markup,\n",
    "                                          classification_rules,\n",
    "                                          category_rules,\n",
    "                                          severity_rules,\n",
    "                                          schema)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(report):\n",
    "    \n",
    "    options = getOptions()\n",
    "\n",
    "    _radnlp_rules = rules.read_rules(options[\"rules\"])\n",
    "    _schema = schema.read_schema(options[\"schema\"])\n",
    "    #_schema = readSchema(options[\"schema\"])\n",
    "    modifiers = itemData.itemData()\n",
    "    targets = itemData.itemData()\n",
    "    for kb in options['lexical_kb']:\n",
    "        modifiers.extend( itemData.instantiateFromCSVtoitemData(kb) )\n",
    "    for kb in options['domain_kb']:\n",
    "        targets.extend( itemData.instantiateFromCSVtoitemData(kb) )\n",
    "    analyze_report(report, modifiers, targets, _radnlp_rules, _schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9f0aeb692d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreports\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-863553c7a081>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(report)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'domain_kb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mitemData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstantiateFromCSVtoitemData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0manalyze_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_radnlp_rules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-eebfa7d940d1>\u001b[0m in \u001b[0;36manalyze_report\u001b[0;34m(report, modifiers, targets, rules, schema)\u001b[0m\n\u001b[1;32m      8\u001b[0m     markup = utils.mark_report(split.get_sentences(report),\n\u001b[1;32m      9\u001b[0m                          \u001b[0mmodifiers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                          targets)\n\u001b[0m\u001b[1;32m     11\u001b[0m     return  classify.classify_document_targets(markup,\n\u001b[1;32m     12\u001b[0m                                           \u001b[0mclassification_rules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brian/anaconda/envs/uuds4health/lib/python3.5/site-packages/radnlp-0.2.0.4-py3.5.egg/radnlp/utils.py\u001b[0m in \u001b[0;36mmark_report\u001b[0;34m(report, modifiers, targets)\u001b[0m\n\u001b[1;32m     69\u001b[0m     return _merge_markups([markup_sentence(s,\n\u001b[1;32m     70\u001b[0m                                           \u001b[0mmodifiers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                                           targets) for s in report])\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brian/anaconda/envs/uuds4health/lib/python3.5/site-packages/radnlp-0.2.0.4-py3.5.egg/radnlp/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m     return _merge_markups([markup_sentence(s,\n\u001b[1;32m     70\u001b[0m                                           \u001b[0mmodifiers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                                           targets) for s in report])\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brian/anaconda/envs/uuds4health/lib/python3.5/site-packages/radnlp-0.2.0.4-py3.5.egg/radnlp/utils.py\u001b[0m in \u001b[0;36mmarkup_sentence\u001b[0;34m(s, modifiers, targets)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mmarkup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyConText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConTextMarkup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mmarkup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetRawText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mmarkup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mmarkup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkItems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"modifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmarkup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkItems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brian/anaconda/envs/uuds4health/lib/python3.5/site-packages/pyConTextNLP/pyConTextGraph.py\u001b[0m in \u001b[0;36mcleanText\u001b[0;34m(self, stripNonAlphaNumeric, stripNumbers)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;31m# clean up white spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstripNumbers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "main(reports[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codingKey = {1:\"AMBIVALENT\",\n",
    "2: \"Negative/Certain/Acute\",\n",
    "3: \"Negative/Uncertain/Chronic\",\n",
    "4: \"Positive/Uncertain/Chronic\",\n",
    "5: \"Positive/Certain/Chronic\",\n",
    "6: \"Negative/Uncertain/Acute\",\n",
    "7: \"Positive/Uncertain/Acute\",\n",
    "8: \"Positive/Certain/Acute\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"debug\"+\".markup.html\",\"w\") as f0:\n",
    "    f0.write(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with open(options['infile']+\".markup.html\",\"w\") as f0:\n",
    "#     f0.write(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display(HTML(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pec.reports[[\"CTPA\"]][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = list(pec.markups.keys())\n",
    "keys.sort()\n",
    "clrs = {\"pulmonary_embolism\":\"blue\",\n",
    "                                               \"definite_negated_existence\":\"red\",\n",
    "                                               \"probable_negated_existence\":\"indianred\",\n",
    "                                               \"ambivalent_existence\":\"orange\",\n",
    "                                               \"probable_existence\":\"forestgreen\",\n",
    "                                               \"definite_existence\":\"green\",\n",
    "                                               \"historical\":\"goldenrod\",\n",
    "                                               \"acute\":\"golden\"}\n",
    "pec.reports.insert(pec.reports.columns.get_loc('CTPA')+1,\n",
    "                   \"markup\",\n",
    "                   [mark_document_with_html(pec.markups[k][0],colors=clrs) for k in keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = list(pec.markups.keys())\n",
    "keys.sort()\n",
    "\n",
    "pec.reports.insert(pec.reports.columns.get_loc(u'markup')+1,\n",
    "                   \"ConText Coding\",\n",
    "                   [codingKey.get(pec.markups[k][1].get(\"pulmonary_embolism\",[None])[0],\"NA\") for k in keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pec.markups[10][1].get(\"pulmonary_embolism\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pec.markups[10][1].get(\"pulmonary_embolism\",[None])[0],\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pec.reports[['CTPA','markup','ConText Coding']][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pec.reports.to_excel(os.path.join(UTAHDATA,\"test.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def view_markup(reports,i):\n",
    "    data = reports[i]\n",
    "    mt=mark_document_with_html(data[0],colors={\"pulmonary_embolism\":\"blue\",\n",
    "                                               \"definite_negated_existence\":\"red\",\n",
    "                                               \"probable_negated_existence\":\"indianred\",\n",
    "                                               \"ambivalent_existence\":\"orange\",\n",
    "                                               \"probable_existence\":\"forestgreen\",\n",
    "                                               \"definite_existence\":\"green\",\n",
    "                                               \"historical\":\"goldenrod\",\n",
    "                                               \"acute\":\"golden\"})\n",
    "    txt = \"\"\"<table style=\"width:100\"><caption>PE Finder Case Review</caption><tr><th>report</th><th>classification</th></tr>\n",
    "            <tr><td width='500'>%s</td><td width='200'>%s</td></tr></table>\"\"\"%(mt,codingKey.get(data[1].get(\"pulmonary_embolism\",[None])[0],\"NA\"))\n",
    "\n",
    "    display(HTML(txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = interact(view_markup,reports=fixed(pec.markups),i=widgets.IntSlider(min=0,max=len(pec.markups)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pypyodbc\n",
    "import sqlalchemy\n",
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "connStr = \"Driver=FreeTDS;Server=MSSQL;port=1433;uid=user;pwd=password;database=%s;TDS_Version=8.0;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = os.path.join(DATADIR,\"Amil\",\"TestAccess.mdb\")\n",
    "print os.path.exists(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connStr = connStr%db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connEncodedStr = urllib.quote_plus(connStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"mssql+pyodbc:///?odbc_connect={}\".format(connEncodedStr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(\"mssql+pypyodbc:///%s\"%db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in engine.execute('select * from myTable'):\n",
    "    print (row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
